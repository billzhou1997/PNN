{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13b6cac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard python imports\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "# pytorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "729279e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fieldupdate3(T=10,size=100,E=ez,Hx=hx,Hy=hy,Eps=Eps):\n",
    "    E_sum=0\n",
    "    imp0=377\n",
    "#     E_history=[]\n",
    "#     Hx_history=[]\n",
    "#     Hy_history=[]\n",
    "#     test=[]\n",
    "    for t in range(T):\n",
    "        for i in range(size):\n",
    "            for j in range(size-1):\n",
    "                Hx[i][j]=Hx[i][j]+(E[i][j+1]-E[i][j])/imp0/2/Eps[i][j]\n",
    "\n",
    "        for i in range(size-1):\n",
    "            for j in range(size):\n",
    "                \n",
    "                Hy[i][j]=Hy[i][j]+(E[i+1][j]-E[i][j])/imp0/2\n",
    "                \n",
    "                \n",
    "        for i in range(size-1):\n",
    "            for j in range(size-1):\n",
    "                E[i+1][j+1]=E[i+1][j+1]+(Hx[i+1][j+1]+Hy[i+1][j+1]-Hx[i+1][j]-Hy[i][j+1])*imp0/2\n",
    "        #E[int(size/4)][int(size/4)]+=math.sin(0.1*t)\n",
    "        E[int(size/2)][int(size/2)]+=math.sin(0.1*t)\n",
    "        #E[int(size/2)][int(size/2)+1]+=math.sin(0.1*t)\n",
    "        #E[int(size/2)][int(size/2)]+=math.exp(-(t+1-0.3*size)*(t+1-0.3*size)/100)\n",
    "        E_sum+= E[int(size/4)][int(size/4)]\n",
    "#         test.append(E[int(0.5*size)])\n",
    "#         E_history.append(E.copy())\n",
    "#         Hx_history.append(Hx.copy())\n",
    "#         Hy_history.append(Hy.copy())\n",
    "#     with open(\"E field history.txt\", 'w') as f:\n",
    "#         for member in E_history:\n",
    "#             f.write(str(member) + '\\n')\n",
    "#     with open(\"Hx field history.txt\", 'w') as f:\n",
    "#         for member in Hx_history:\n",
    "#             f.write(str(member) + '\\n')\n",
    "#     with open(\"Hy field history.txt\", 'w') as f:\n",
    "#         for member in Hy_history:\n",
    "#             f.write(str(member) + '\\n')\n",
    "#     E_history=np.array(E_history)\n",
    "        \n",
    "    return E,E_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7b7f3bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], dtype=torch.float64, requires_grad=True)\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n",
      "tensor([3., 6., 9.], dtype=torch.float64, grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#M=torch.tensor([[1., 1., 1.],\n",
    "#        [1., 1., 1.],\n",
    "#        [1., 1., 1.]], dtype=torch.float64,requires_grad=True)\n",
    "M=torch.zeros((3,3), dtype=torch.float64,requires_grad=True)\n",
    "#M=torch.tensor(M,requires_grad=True)\n",
    "print(M)\n",
    "target=torch.tensor([3.,6.,9.],dtype=torch.float64)\n",
    "#target=target.unsqueeze(1)\n",
    "X=torch.tensor([1.,1.,1.], dtype=torch.float64,requires_grad=True)\n",
    "print(target.size())\n",
    "pred=torch.matmul(M,X)\n",
    "pred=pred.reshape([3,])\n",
    "print(pred.size())\n",
    "print(target-pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "723ee798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.9851, 5.9702, 8.6729], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0360, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([3.0018, 5.9403, 8.7029], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0306, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9794, 5.9626, 8.7328], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0244, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9692, 5.9840, 8.7624], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0192, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9747, 5.9928, 8.7916], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0147, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9855, 5.9899, 8.8203], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0109, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9945, 5.9808, 8.8482], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0078, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9967, 5.9696, 8.8751], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0055, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9927, 5.9598, 8.9008], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0038, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9856, 5.9546, 8.9249], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0026, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9790, 5.9547, 8.9473], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0018, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9760, 5.9590, 8.9675], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0011, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9774, 5.9659, 8.9853], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0006, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9820, 5.9732, 9.0006], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0003, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9874, 5.9789, 9.0131], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0003, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9913, 5.9817, 9.0229], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0003, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9921, 5.9811, 9.0298], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0004, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9898, 5.9777, 9.0341], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0006, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9858, 5.9727, 9.0359], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0007, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9818, 5.9675, 9.0353], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0009, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9796, 5.9634, 9.0327], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0009, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9800, 5.9615, 9.0282], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0009, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9825, 5.9622, 9.0222], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0007, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9859, 5.9649, 9.0151], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0006, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9886, 5.9688, 9.0069], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0004, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9895, 5.9727, 8.9981], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0003, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9884, 5.9755, 8.9890], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0003, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9858, 5.9766, 8.9797], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0004, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9832, 5.9758, 8.9706], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0006, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9816, 5.9735, 8.9618], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0008, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9818, 5.9704, 8.9537], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0011, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9835, 5.9675, 8.9463], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0014, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9858, 5.9657, 8.9398], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0017, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9875, 5.9653, 8.9344], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0019, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9879, 5.9664, 8.9301], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0021, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9869, 5.9686, 8.9269], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0022, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9710, 8.9249], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0022, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9834, 5.9729, 8.9240], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0023, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9827, 5.9738, 8.9242], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0022, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9833, 5.9735, 8.9254], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0022, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9847, 5.9721, 8.9274], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0021, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9862, 5.9702, 8.9301], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0020, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9870, 5.9685, 8.9334], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0019, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9867, 5.9675, 8.9372], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0017, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9855, 5.9674, 8.9411], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0016, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9843, 5.9683, 8.9453], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0014, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9836, 5.9697, 8.9493], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0013, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9837, 5.9711, 8.9532], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0011, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9846, 5.9721, 8.9569], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9857, 5.9723, 8.9601], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0009, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9863, 5.9718, 8.9629], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0008, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9862, 5.9707, 8.9651], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0008, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9854, 5.9695, 8.9668], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0007, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9845, 5.9687, 8.9679], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0008, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9840, 5.9685, 8.9684], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0007, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9842, 5.9689, 8.9684], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0007, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9849, 5.9697, 8.9679], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0007, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9856, 5.9707, 8.9670], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0007, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9859, 5.9713, 8.9657], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0007, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9857, 5.9715, 8.9641], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0008, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9711, 8.9623], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0008, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9845, 5.9704, 8.9604], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0009, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9844, 5.9697, 8.9585], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9847, 5.9692, 8.9566], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9852, 5.9691, 8.9549], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0011, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9856, 5.9695, 8.9533], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0011, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9856, 5.9701, 8.9519], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0011, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9853, 5.9706, 8.9509], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0012, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9848, 5.9709, 8.9500], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0012, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9846, 5.9709, 8.9495], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0012, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9847, 5.9705, 8.9493], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0012, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9850, 5.9701, 8.9493], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0012, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9854, 5.9697, 8.9496], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0012, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9855, 5.9695, 8.9501], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0012, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9853, 5.9696, 8.9508], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0012, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9850, 5.9700, 8.9516], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0012, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9848, 5.9704, 8.9525], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0011, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9848, 5.9706, 8.9534], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0011, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9850, 5.9706, 8.9543], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0011, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9853, 5.9705, 8.9552], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9854, 5.9701, 8.9560], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9852, 5.9699, 8.9567], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9850, 5.9697, 8.9572], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9849, 5.9698, 8.9576], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9849, 5.9700, 8.9579], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9850, 5.9703, 8.9580], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9852, 5.9704, 8.9580], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9853, 5.9705, 8.9578], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9852, 5.9703, 8.9575], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9850, 5.9701, 8.9572], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9849, 5.9700, 8.9568], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9849, 5.9699, 8.9563], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9700, 8.9559], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9852, 5.9701, 8.9554], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9852, 5.9703, 8.9550], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9704, 8.9547], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0011, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9850, 5.9703, 8.9544], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0011, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9850, 5.9702, 8.9541], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0011, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9850, 5.9701, 8.9540], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0011, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9700, 8.9539], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0011, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9852, 5.9700, 8.9539], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0011, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9852, 5.9701, 8.9540], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0011, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9702, 8.9541], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0011, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9850, 5.9703, 8.9543], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0011, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9850, 5.9703, 8.9545], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0011, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9702, 8.9547], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0011, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9701, 8.9549], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9701, 8.9551], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9700, 8.9553], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9850, 5.9701, 8.9555], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9850, 5.9701, 8.9557], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9850, 5.9702, 8.9558], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9702, 8.9559], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9702, 8.9559], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9702, 8.9559], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9701, 8.9558], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9850, 5.9701, 8.9558], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9850, 5.9701, 8.9557], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9701, 8.9556], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9702, 8.9554], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9702, 8.9553], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9702, 8.9552], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9850, 5.9702, 8.9551], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9850, 5.9701, 8.9550], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9701, 8.9550], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9701, 8.9549], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9701, 8.9549], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9702, 8.9549], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9702, 8.9549], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9702, 8.9549], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9702, 8.9550], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9701, 8.9551], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9701, 8.9551], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9701, 8.9552], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9701, 8.9552], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9702, 8.9553], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9702, 8.9553], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9702, 8.9554], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9702, 8.9554], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9701, 8.9554], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9701, 8.9554], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9701, 8.9554], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9701, 8.9554], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9702, 8.9553], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9702, 8.9553], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9702, 8.9553], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9701, 8.9552], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9701, 8.9552], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9701, 8.9552], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9701, 8.9552], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9702, 8.9551], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9702, 8.9551], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9702, 8.9551], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9702, 8.9551], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9701, 8.9551], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9701, 8.9552], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9701, 8.9552], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9701, 8.9552], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9702, 8.9552], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9702, 8.9552], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9702, 8.9552], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9701, 8.9553], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9701, 8.9553], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9701, 8.9553], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9701, 8.9553], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9702, 8.9553], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9702, 8.9553], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9702, 8.9553], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9702, 8.9553], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9701, 8.9552], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9701, 8.9552], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9701, 8.9552], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9701, 8.9552], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9702, 8.9552], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9702, 8.9552], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9702, 8.9552], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9701, 8.9552], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9701, 8.9552], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9701, 8.9552], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9701, 8.9552], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9702, 8.9552], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9702, 8.9552], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9702, 8.9552], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9701, 8.9552], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9701, 8.9552], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9701, 8.9552], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9701, 8.9552], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9702, 8.9552], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9702, 8.9552], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9702, 8.9552], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9701, 8.9552], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9701, 8.9552], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9701, 8.9552], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9701, 8.9552], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9701, 8.9552], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9702, 8.9552], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9702, 8.9552], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9701, 8.9552], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9701, 8.9552], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor([2.9851, 5.9701, 8.9552], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "tensor([3., 6., 9.], dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "criterion=nn.MSELoss()\n",
    "import torch.optim as optim\n",
    "optimizer = torch.optim.Adam([M], lr=0.01, betas=(0.9, 0.999), eps=1e-07, weight_decay=0.01)  #adam optimizer\n",
    "    \n",
    "for i in range(200):\n",
    "    optimizer.zero_grad()   # zero the gradient buffers\n",
    "    output = torch.matmul(M,X)\n",
    "    print(output)\n",
    "    print(target)\n",
    "    loss = criterion(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss)\n",
    "    #print(X)\n",
    "    #print(M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a64898ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9950, 0.9950, 0.9950],\n",
      "        [1.9900, 1.9900, 1.9900],\n",
      "        [2.9851, 2.9851, 2.9851]], dtype=torch.float64, requires_grad=True)\n",
      "tensor([1., 1., 1.], dtype=torch.float64, requires_grad=True)\n",
      "tensor([2.9851, 5.9701, 8.9552], dtype=torch.float64, grad_fn=<MvBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(M)\n",
    "print(X)\n",
    "print(torch.matmul(M,X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6dff77f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "size=10\n",
    "ez=torch.zeros((size,size))\n",
    "hx=torch.zeros((size,size))\n",
    "hy=torch.zeros((size,size))\n",
    "Eps=torch.ones((size,size),requires_grad=True)\n",
    "target=torch.tensor([[0.1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3070a9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 23.354227781295776 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "\n",
    "E,E_sum=fieldupdate3(10,size,ez,hx,hy,Eps)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ae303c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0193, grad_fn=<AddBackward0>)\n",
      "tensor([[0.1000]])\n",
      "tensor(0.0065, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0241, grad_fn=<AddBackward0>)\n",
      "tensor([[0.1000]])\n",
      "tensor(0.0058, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0303, grad_fn=<AddBackward0>)\n",
      "tensor([[0.1000]])\n",
      "tensor(0.0049, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0381, grad_fn=<AddBackward0>)\n",
      "tensor([[0.1000]])\n",
      "tensor(0.0038, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0472, grad_fn=<AddBackward0>)\n",
      "tensor([[0.1000]])\n",
      "tensor(0.0028, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = torch.optim.Adam([Eps], lr=0.1, betas=(0.9, 0.999), eps=1e-07, weight_decay=0.01)  #adam optimizer\n",
    "    \n",
    "for i in range(5):\n",
    "    optimizer.zero_grad()   # zero the gradient buffers\n",
    "    ez=torch.zeros((size,size))\n",
    "    hx=torch.zeros((size,size))\n",
    "    hy=torch.zeros((size,size))\n",
    "    E,E_sum=fieldupdate3(10,size,ez,hx,hy,Eps)\n",
    "    output = E_sum\n",
    "    print(output)\n",
    "    print(target)\n",
    "    #torch.autograd.set_detect_anomaly(True)\n",
    "    loss = criterion(output, target)\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    print(loss)\n",
    "    #print(X)\n",
    "    #print(M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9f0bf620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0557, grad_fn=<AddBackward0>)\n",
      "tensor([[0.1000]])\n",
      "tensor(0.0009, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0580, grad_fn=<AddBackward0>)\n",
      "tensor([[0.1000]])\n",
      "tensor(0.0010, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "tensor([[0.1000]])\n",
      "tensor(0.0014, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1492, grad_fn=<AddBackward0>)\n",
      "tensor([[0.1000]])\n",
      "tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "tensor(2.2799, grad_fn=<AddBackward0>)\n",
      "tensor([[0.1000]])\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = torch.optim.Adam([Eps], lr=0.1, betas=(0.9, 0.999), eps=1e-07, weight_decay=0.01)  #adam optimizer\n",
    "    \n",
    "for i in range(5):\n",
    "    optimizer.zero_grad()   # zero the gradient buffers\n",
    "    ez=torch.zeros((size,size))\n",
    "    hx=torch.zeros((size,size))\n",
    "    hy=torch.zeros((size,size))\n",
    "    E,E_sum=fieldupdate3(10,size,ez,hx,hy,Eps)\n",
    "    output = E_sum\n",
    "    print(output)\n",
    "    print(target)\n",
    "    #torch.autograd.set_detect_anomaly(True)\n",
    "    loss = criterion(E[4][4], target)\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    print(loss)\n",
    "    #print(X)\n",
    "    #print(M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e350347a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1237, grad_fn=<SelectBackward>)\n",
      "tensor(2.2799, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(E[4][4])\n",
    "print(E_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f7c1c2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0349, 0.0349, 0.0349, 0.0349, 0.0349, 0.0349, 0.0349, 0.0349, 0.0349,\n",
      "         0.0349],\n",
      "        [0.0349, 0.0349, 0.0349, 0.0349, 0.0349, 0.0349, 0.0349, 0.0349, 0.0349,\n",
      "         0.0349],\n",
      "        [0.0349, 0.0373, 0.0311, 0.0637, 0.1012, 0.0607, 0.0349, 0.0349, 0.0349,\n",
      "         0.0349],\n",
      "        [0.0349, 0.0360, 0.1651, 0.2871, 0.3122, 0.2626, 0.1622, 0.0349, 0.0349,\n",
      "         0.0349],\n",
      "        [0.0349, 0.3020, 0.3859, 0.4341, 0.4356, 0.4189, 0.3656, 0.2405, 0.0349,\n",
      "         0.0349],\n",
      "        [0.0349, 0.2510, 0.3738, 0.4199, 0.4346, 0.4358, 0.3787, 0.2911, 0.0349,\n",
      "         0.0349],\n",
      "        [0.0349, 0.0349, 0.1617, 0.2645, 0.3102, 0.2807, 0.1656, 0.0349, 0.0349,\n",
      "         0.0349],\n",
      "        [0.0349, 0.0349, 0.0349, 0.0606, 0.1008, 0.0638, 0.0349, 0.0349, 0.0349,\n",
      "         0.0349],\n",
      "        [0.0349, 0.0349, 0.0349, 0.0349, 0.0349, 0.0349, 0.0349, 0.0349, 0.0349,\n",
      "         0.0349],\n",
      "        [0.0349, 0.0349, 0.0349, 0.0349, 0.0349, 0.0349, 0.0349, 0.0349, 0.0349,\n",
      "         0.0349]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(Eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8eecfc9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c72039f520>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.imshow(Eps.detach().numpy(),origin='lower')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733257d6",
   "metadata": {},
   "source": [
    "limit value of Eps matrix\n",
    "expand size\n",
    "get fdtd package work\n",
    "tune hyper parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7720fa60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
