{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94a7aa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard python imports\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "# pytorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c92988c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('exp_io_data\\CoupledPendula_mean_in7_out7_Tmax1.0_data.npz')\n",
    "for key, val in data.items():\n",
    "\n",
    "    exec(key +'=val')\n",
    "x=xlist\n",
    "y=exp_out_list\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fe5e3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.24749702 0.02014035 0.8485794  ... 0.08696669 0.99749106 0.38496768]\n",
      " [0.75097805 0.60711515 0.67705935 ... 0.44351715 0.26912165 0.6546309 ]\n",
      " [0.5515969  0.85570264 0.12367398 ... 0.65876925 0.5144654  0.21687716]\n",
      " ...\n",
      " [0.7910753  0.15300226 0.25244486 ... 0.79041374 0.23180968 0.36545432]\n",
      " [0.8996175  0.3548531  0.558233   ... 0.77378803 0.30139804 0.52732176]\n",
      " [0.45920014 0.6914123  0.7981772  ... 0.7037045  0.4136985  0.35502923]]\n"
     ]
    }
   ],
   "source": [
    "x_in=x[:,0:7]\n",
    "x_para=x[:,7:14]\n",
    "#print(x_in)\n",
    "#print(x_para)\n",
    "def pre_processing_x(x):\n",
    "    n,d=x.shape\n",
    "    n= int(n/2)\n",
    "    d= int(d/2)\n",
    "    x_in=x[:,0:d]\n",
    "    x_para=x[:,d:2*d]\n",
    "    x_train=x_in[0:n:]\n",
    "    x_test=x_in[n:2*n,:]\n",
    "    x_train_para=x_para[0:n,:]\n",
    "    x_test_para=x_para[n:n*2,:]\n",
    "    return x_train,x_test,x_train_para, x_test_para\n",
    "a,b,c,d=pre_processing_x(x)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6fc4b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 2000, 7)\n",
      "(30, 2000, 7)\n",
      "torch.Size([2000, 30, 14])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_x=y[0,:,:,:,0]\n",
    "y_v=y[0,:,:,:,1]/30\n",
    "print(y_x.shape)\n",
    "print(y_v.shape)\n",
    "\n",
    "y_new=np.concatenate((y_x,y_v),axis=2)\n",
    "y_new=torch.from_numpy(y_new)\n",
    "y_new=torch.transpose(y_new,0,1)\n",
    "# print(y_new[1,1:2,:])\n",
    "# print(y_new[1,2:3,:])\n",
    "print(y_new.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c153c785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net2(\n",
      "  (rnn): RNN(14, 14, num_layers=5, batch_first=True)\n",
      "  (fc): Linear(in_features=14, out_features=14, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class Net2(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net2, self).__init__()\n",
    "\n",
    "        self.rnn = nn.RNN(14,14, 5,batch_first=True)\n",
    "        self.fc = nn.Linear(14,14)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out, _ =self.rnn(x)\n",
    "        #out =out[:,-1,:]\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "net2 = Net2()\n",
    "print(net2)\n",
    "\n",
    "\n",
    "#out0=net(in0)\n",
    "#out1=net(out0)...\n",
    "# full_data=30*14\n",
    "# net(in5)=full_data[0:5,:]\n",
    "#out0=net(in0)\n",
    "#y_target=full_data[1:6,:]\n",
    "#loss = mse(y_target, net(in5) )\n",
    "#loss= sum (out[i]-in[i+1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f687626c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "torch.Size([14, 14])\n"
     ]
    }
   ],
   "source": [
    "params = list(net2.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e9490aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2000, 5, 14])\n",
      "torch.Size([2000, 5, 14])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input = y_new[:,0:5,:]\n",
    "print(input.shape)\n",
    "out = net2(input)\n",
    "#print(out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "72a86957",
   "metadata": {},
   "outputs": [],
   "source": [
    "net2.zero_grad()\n",
    "out.backward(torch.randn(2000,5,14))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1acdb550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2000, 5, 14])\n",
      "tensor(0.3054, grad_fn=<MseLossBackward>)\n",
      "torch.Size([2000, 5, 14])\n"
     ]
    }
   ],
   "source": [
    "target= y_new[:,1:6,:]\n",
    "print(target.shape)\n",
    "criterion=nn.MSELoss()\n",
    "loss=criterion(out,target)\n",
    "print(loss)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e5a53db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3052, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3053, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3052, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3052, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3052, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3052, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3052, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3052, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3052, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3052, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3052, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3052, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3052, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3052, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3052, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3052, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3052, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3052, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3052, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3052, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = torch.optim.Adam(params, lr=0.01, betas=(0.9, 0.999), eps=1e-09, weight_decay=0.1, amsgrad=False)  #adam optimizer\n",
    "    \n",
    "for i in range(20):\n",
    "    optimizer.zero_grad()   # zero the gradient buffers\n",
    "    output = net2(input)\n",
    "    loss = criterion(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cba61ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2000, 14])\n"
     ]
    }
   ],
   "source": [
    "output_plot=output[:,6,:]\n",
    "print(output_plot.shape)\n",
    "target_plot= y_new[:,7,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae78d6db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'y_pred')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(output_plot.detach().flatten(), target_plot.detach().numpy().flatten(), '.')\n",
    "plt.title('Training')\n",
    "plt.xlabel('y')\n",
    "plt.ylabel('y_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c198fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9185, 0.8238, 0.9963,  ..., 0.6682, 0.7984, 0.1572],\n",
      "        [0.3933, 0.9606, 0.9643,  ..., 0.7520, 0.4876, 0.8830],\n",
      "        [0.6237, 0.5434, 0.0358,  ..., 0.9932, 0.3677, 0.0729],\n",
      "        ...,\n",
      "        [0.4289, 0.7778, 0.2352,  ..., 0.7652, 0.4831, 0.2972],\n",
      "        [0.2022, 0.3456, 0.6055,  ..., 0.7885, 0.4216, 0.8429],\n",
      "        [0.8430, 0.8307, 0.3663,  ..., 0.3736, 0.5766, 0.7607]])\n"
     ]
    }
   ],
   "source": [
    "x_test=torch.tensor(x[1000:2000,:])\n",
    "x_para_test=torch.from_numpy(x_para[1000:2000,:])\n",
    "print(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "122b0a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 1, 14])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "input must have 3 dimensions, got 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-2e6bfa592afc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my_test_new\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtest_out\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnet2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-43eb8f69c712>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[1;31m#out =out[:,-1,:]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    263\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mhx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m         \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m         \u001b[0m_impl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_rnn_impls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m         \u001b[0mexpected_hidden_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_expected_hidden_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mcheck_input\u001b[1;34m(self, input, batch_sizes)\u001b[0m\n\u001b[0;32m    199\u001b[0m         \u001b[0mexpected_input_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mexpected_input_dim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m             raise RuntimeError(\n\u001b[0m\u001b[0;32m    202\u001b[0m                 'input must have {} dimensions, got {}'.format(\n\u001b[0;32m    203\u001b[0m                     expected_input_dim, input.dim()))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: input must have 3 dimensions, got 2"
     ]
    }
   ],
   "source": [
    "y_test=y_new[1000:2000,6:7,:]\n",
    "print(y_test.shape)\n",
    "y_test_new=torch.transpose(y_test,1,2).squeeze(2)\n",
    "\n",
    "test_out=net2(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262c25c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7489bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dt_exp_comparison(yexp, ypred):\n",
    "\n",
    "    fig, axs = plt.subplots(nrows = 3, ncols = 3, figsize = [10,8], dpi = 100, sharex=True, sharey=True)\n",
    "    for i in range(9):\n",
    "        plt.sca(axs.flatten()[i])\n",
    "        plt.plot(ypred[i], '.-', lw = 1, c = 'k', alpha = 0.5, label = 'digital twin prediction')\n",
    "        plt.plot(yexp[i], '.-', lw = 1, c = 'b', alpha = 0.5, label = 'experimental outcome')\n",
    "        plt.xlabel('# pendulum')\n",
    "        plt.ylabel('output angle')\n",
    "        plt.title(f'Initial conditions {i}')\n",
    "        plt.grid()\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('img/coupled_pendula_dt_examples.png')\n",
    "    plt.show()\n",
    "    \n",
    "#plot_dt_exp_comparison(y_test_new,2*test_out.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f07a100a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_out' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-012f559573ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_dt_exp_comparison\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_new\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtest_out\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'test_out' is not defined"
     ]
    }
   ],
   "source": [
    "plot_dt_exp_comparison(y_test_new,2*test_out.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb087b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.2375,  0.2631, -0.4102,  0.3369,  0.7218,  0.0728, -0.1361,\n",
      "          -0.6703, -0.0438, -0.0732,  0.3423, -0.7693,  0.2935, -0.3053,\n",
      "           0.2523, -0.0571, -0.0202,  0.2989, -0.5673,  0.5073],\n",
      "         [ 0.6162,  0.1850,  0.4126,  0.7775, -0.0137, -0.0534,  0.3354,\n",
      "           0.7826,  0.0203, -0.7898, -0.4899, -0.4363,  0.2901, -0.1991,\n",
      "           0.8144, -0.7364, -0.2497, -0.1143,  0.2171, -0.6417],\n",
      "         [-0.4599, -0.0467, -0.2275, -0.4104, -0.5177, -0.3929,  0.2770,\n",
      "           0.8107,  0.1556, -0.0995, -0.1703, -0.8356, -0.2047,  0.1082,\n",
      "          -0.4893, -0.3708,  0.2517, -0.5033,  0.1679, -0.7449]],\n",
      "\n",
      "        [[ 0.5826, -0.2345, -0.1166, -0.1942, -0.4757,  0.3322, -0.5826,\n",
      "          -0.3270,  0.2118, -0.0024, -0.1701, -0.6327,  0.2515,  0.1649,\n",
      "          -0.0095, -0.0376, -0.2996, -0.0382, -0.7207, -0.1265],\n",
      "         [-0.0549, -0.0493,  0.2682,  0.3365, -0.1387,  0.2228, -0.3334,\n",
      "           0.1602, -0.3064, -0.0831,  0.2582, -0.5007,  0.0114, -0.0103,\n",
      "           0.2658, -0.5293,  0.2877, -0.3719, -0.4715, -0.1208],\n",
      "         [-0.3125, -0.3016, -0.0204,  0.0847, -0.0077,  0.4658, -0.2452,\n",
      "           0.1091, -0.3852, -0.0755,  0.0776, -0.1404, -0.0011,  0.4005,\n",
      "           0.2406, -0.8163,  0.1532, -0.4261, -0.3656, -0.2762]],\n",
      "\n",
      "        [[ 0.5054, -0.4136, -0.2962,  0.5057,  0.4392, -0.2878, -0.4731,\n",
      "          -0.0941, -0.6872,  0.1761, -0.0538, -0.4454, -0.3259,  0.0369,\n",
      "           0.0860, -0.3703,  0.2451, -0.2202, -0.4112,  0.1488],\n",
      "         [ 0.4517, -0.3042,  0.0795,  0.3457, -0.0103,  0.0512, -0.3927,\n",
      "           0.0322, -0.4201, -0.2221, -0.1264, -0.3993, -0.1371,  0.1127,\n",
      "           0.2265, -0.4175, -0.0568, -0.0578, -0.5661,  0.0356],\n",
      "         [ 0.3689, -0.2880, -0.0834,  0.2502, -0.3059,  0.0103, -0.1698,\n",
      "           0.0342, -0.4672, -0.2911, -0.0625, -0.1386, -0.1101,  0.2326,\n",
      "           0.3360, -0.5214, -0.4251,  0.0659, -0.5549,  0.0030]],\n",
      "\n",
      "        [[ 0.5662, -0.3924,  0.2271, -0.0280, -0.6562, -0.1666, -0.6108,\n",
      "          -0.1970, -0.3824,  0.0868,  0.2201, -0.2143, -0.5242,  0.4802,\n",
      "           0.0935, -0.4634,  0.0200, -0.1722, -0.6964, -0.0753],\n",
      "         [ 0.3622, -0.3244, -0.2337,  0.1243,  0.4384, -0.3291, -0.1694,\n",
      "          -0.0844, -0.5373,  0.0572,  0.3523, -0.6900, -0.3768, -0.0565,\n",
      "          -0.1246, -0.3254, -0.0832, -0.4805, -0.3972,  0.5157],\n",
      "         [ 0.5297, -0.2339,  0.2699,  0.2406, -0.4258, -0.2221, -0.5343,\n",
      "          -0.1382, -0.3427, -0.1200,  0.0430, -0.1669, -0.3750,  0.3879,\n",
      "           0.3565, -0.6322, -0.0713, -0.2206, -0.5769, -0.0319]],\n",
      "\n",
      "        [[ 0.3071, -0.5472, -0.3569,  0.1084, -0.3758,  0.1539, -0.4219,\n",
      "          -0.1505, -0.4635,  0.0516,  0.3275, -0.5479, -0.3174, -0.0627,\n",
      "           0.2701, -0.5778, -0.3365, -0.0482, -0.7135, -0.2598],\n",
      "         [ 0.1495, -0.4303, -0.2355, -0.1277, -0.3989, -0.3064, -0.5847,\n",
      "          -0.1632, -0.2620, -0.0534,  0.2587, -0.5978, -0.1610,  0.0980,\n",
      "          -0.0823, -0.2441,  0.0828, -0.1782, -0.4260,  0.1333],\n",
      "         [ 0.4282, -0.3873, -0.5432,  0.2686,  0.0479, -0.4013, -0.4194,\n",
      "           0.1998, -0.5793,  0.2235,  0.2342, -0.6091, -0.2176, -0.0401,\n",
      "           0.0412, -0.6277, -0.0740, -0.3508, -0.5368,  0.2850]]],\n",
      "       grad_fn=<StackBackward>)\n"
     ]
    }
   ],
   "source": [
    "rnn = nn.RNN(10, 20, 2)\n",
    "input = torch.randn(5, 3, 10)\n",
    "h0 = torch.randn(2, 3, 20)\n",
    "output, hn = rnn(input, h0)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c01430",
   "metadata": {},
   "source": [
    "params2 = list(net2.parameters())\n",
    "print(len(params2))\n",
    "print(params2[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b558da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data=torch.tensor(x)\n",
    "input = x_data\n",
    "out = net2(input)\n",
    "print(out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8ad80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target=y1[0:1000,:,:]\n",
    "target_new=target.view(1000,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5261484e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = torch.optim.Adam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-06, weight_decay=0.1, amsgrad=False)  #adam optimizer\n",
    "    \n",
    "for i in range(200):\n",
    "    optimizer.zero_grad()   # zero the gradient buffers\n",
    "    output = net2(input)\n",
    "    loss = criterion(output, target_new)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e684b295",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
