{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94a7aa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard python imports\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "# pytorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c92988c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xlist\n",
      "exp_out_list\n"
     ]
    }
   ],
   "source": [
    "data = np.load('exp_io_data\\CoupledPendula_mean_in7_out7_Tmax1.0_data.npz')\n",
    "for key, val in data.items():\n",
    "    print(key)\n",
    "    exec(key +'=val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42f5386a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 14)\n",
      "(2, 30, 2000, 7, 2)\n"
     ]
    }
   ],
   "source": [
    "x=xlist\n",
    "y=exp_out_list\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afb0a6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 7)\n"
     ]
    }
   ],
   "source": [
    "x_in=x[:,0:7]\n",
    "x_para=x[:,7:14]\n",
    "#print(x_in)\n",
    "#print(x_para)\n",
    "v_int=np.zeros((2000,7))\n",
    "x_train=x_in[0:1000,:]\n",
    "x_train2=x[0:1000,:]\n",
    "print(x_train.shape)\n",
    "#print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fe5e3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 2000, 7)\n",
      "(29, 2000, 7)\n",
      "(30, 2000, 7)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_temp2=y[0,0:29,:,:,0]\n",
    "y_temp1=y[0,1:30,:,:,0]\n",
    "print(y_temp2.shape)\n",
    "print(y_temp1.shape)\n",
    "y_v=(y_temp2-y_temp1)*30\n",
    "y_0=np.zeros((1,2000,7))\n",
    "y_v=np.concatenate((y_0,y_v),axis=0)\n",
    "print(y_v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6fc4b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 30, 2000, 7, 2)\n",
      "torch.Size([2000, 30, 14])\n"
     ]
    }
   ],
   "source": [
    "#y1=y[0:1,29:30,:,:,0:1]\n",
    "print(y.shape)\n",
    "y_x=y[0,:,:,:,0]\n",
    "y_new=np.concatenate((y_x,y_v),axis=2)\n",
    "y_new=torch.from_numpy(y_new)\n",
    "y_new=torch.transpose(y_new,0,1)\n",
    "print(y_new.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "961b5ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 1, 14])\n"
     ]
    }
   ],
   "source": [
    "F=3 #Fth frame\n",
    "\n",
    "y_train=y_new[0:1000,F:F+1,:]\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c153c785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (layer1): Linear(in_features=14, out_features=14, bias=True)\n",
      "  (layer2): Linear(in_features=14, out_features=14, bias=True)\n",
      "  (layer3): Linear(in_features=14, out_features=14, bias=True)\n",
      "  (layer4): Linear(in_features=14, out_features=14, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Linear(14, 14 ,bias=True)\n",
    "        self.layer2 = nn.Linear(14, 14,bias=True)\n",
    "        self.layer3 = nn.Linear(14, 14,bias=True)\n",
    "        #self.layer4 = nn.Linear(14, 14,bias=True)\n",
    "        #self.layer5 = nn.Linear(14, 14,bias=True)\n",
    "        self.layer4 = nn.Linear(14, 14,bias=True)\n",
    "    def forward(self, x,activation=\"RELU\"):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        \n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        x = x+torch.sigmoid(self.layer1(x))\n",
    "        x = x+torch.sigmoid(self.layer2(x))\n",
    "        x = x+torch.sigmoid(self.layer3(x))\n",
    "        #x = x+torch.sigmoid(self.layer4(x))\n",
    "        #x = x+torch.sigmoid(self.layer5(x))\n",
    "        x = self.layer4(x)\n",
    "        #x = F.relu(self.layer4(x))\n",
    "        #x = F.relu(self.layer5(x))\n",
    "        #x = torch.sigmoid(self.layer6(x))\n",
    "        return x.float()\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c247b679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (layer1): Linear(in_features=14, out_features=14, bias=True)\n",
      "  (layer2): Linear(in_features=14, out_features=14, bias=True)\n",
      "  (layer3): Linear(in_features=14, out_features=14, bias=True)\n",
      "  (layer4): Linear(in_features=14, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Linear(14, 14 ,bias=True)\n",
    "        self.layer2 = nn.Linear(14, 14,bias=True)\n",
    "        self.layer3 = nn.Linear(14, 14,bias=True)\n",
    "        #self.layer4 = nn.Linear(14, 14,bias=True)\n",
    "        #self.layer5 = nn.Linear(14, 14,bias=True)\n",
    "        self.layer4 = nn.Linear(14, 7,bias=True)\n",
    "    def forward(self, x,activation=\"RELU\"):\n",
    "        \n",
    "        if activation==\"RELU\":\n",
    "            x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "            x = x+0.1*(self.layer1(x))\n",
    "            x = x+0.1*(self.layer2(x))\n",
    "            x = x+0.1*(self.layer3(x))\n",
    "            #x = x+torch.sigmoid(self.layer4(x))\n",
    "            #x = x+torch.sigmoid(self.layer5(x))\n",
    "            x = self.layer4(x)\n",
    "            #x = F.relu(self.layer4(x))\n",
    "            #x = F.relu(self.layer5(x))\n",
    "            #x = torch.sigmoid(self.layer6(x))\n",
    "        if activation==\"SIG\":\n",
    "            x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "            x = x+torch.sigmoid(self.layer1(x))\n",
    "            x = x+torch.sigmoid(self.layer2(x))\n",
    "            x = x+torch.sigmoid(self.layer3(x))\n",
    "            #x = x+torch.sigmoid(self.layer4(x))\n",
    "            #x = x+torch.sigmoid(self.layer5(x))\n",
    "            x = self.layer4(x)\n",
    "            #x = F.relu(self.layer4(x))\n",
    "            #x = F.relu(self.layer5(x))\n",
    "            #x = torch.sigmoid(self.layer6(x))            \n",
    "        return x.float()\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f687626c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "torch.Size([14, 14])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e9490aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.9287,  0.8485,  2.9031,  ...,  1.4912,  0.5082,  1.9616],\n",
      "        [-2.9467,  0.5268,  2.8854,  ...,  1.4895,  0.4990,  1.9502],\n",
      "        [-2.9327,  0.9733,  2.9170,  ...,  1.2457,  0.2563,  2.2040],\n",
      "        ...,\n",
      "        [-2.9613,  0.4369,  2.8786,  ...,  1.4425,  0.3197,  1.8224],\n",
      "        [-3.1352,  0.3811,  2.9775,  ...,  1.4827,  0.1828,  1.9060],\n",
      "        [-3.0442,  0.6493,  2.7635,  ...,  1.5666,  0.3755,  2.1952]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "torch.Size([1000, 14])\n"
     ]
    }
   ],
   "source": [
    "x_data=torch.tensor(x_train2)\n",
    "input = x_data\n",
    "out = net(input,\"SIG\")\n",
    "print(out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "72a86957",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(1000,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acdb550",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "df172deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 14])\n",
      "tensor(27.5810, dtype=torch.float64, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "target=y_train\n",
    "target_new=target.view(1000,14)\n",
    "print(target_new.shape)\n",
    "criterion=nn.MSELoss()\n",
    "loss=criterion(out,target_new)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "685a6e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -0.6331,  -1.0633,   0.6323,  ..., -11.2331,  15.7281,  -4.7278],\n",
      "        [  0.5520,   0.3416,   0.4333,  ...,  -0.1292,  -6.7235,   5.0746],\n",
      "        [  0.1080,   0.5514,  -0.8419,  ...,   3.8873,   1.0384,  -7.9504],\n",
      "        ...,\n",
      "        [  0.4511,  -0.8309,  -0.5465,  ...,   7.9163,  -9.3738,  -3.0244],\n",
      "        [  1.0231,  -0.1878,  -0.0298,  ...,  11.8963,  -8.0969,  -0.2513],\n",
      "        [ -0.0641,   0.4567,   0.9569,  ...,   4.4670,  -2.0576,  -4.3529]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-2.9287,  0.8485,  2.9031,  ...,  1.4912,  0.5082,  1.9616],\n",
      "        [-2.9467,  0.5268,  2.8854,  ...,  1.4895,  0.4990,  1.9502],\n",
      "        [-2.9327,  0.9733,  2.9170,  ...,  1.2457,  0.2563,  2.2040],\n",
      "        ...,\n",
      "        [-2.9613,  0.4369,  2.8786,  ...,  1.4425,  0.3197,  1.8224],\n",
      "        [-3.1352,  0.3811,  2.9775,  ...,  1.4827,  0.1828,  1.9060],\n",
      "        [-3.0442,  0.6493,  2.7635,  ...,  1.5666,  0.3755,  2.1952]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "torch.Size([1000, 14])\n",
      "torch.Size([1000, 14])\n",
      "tensor(27.5810, dtype=torch.float64, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print((target_new))\n",
    "output = net(input)\n",
    "print((output))\n",
    "print((target_new.shape))\n",
    "print((output.shape))\n",
    "\n",
    "optimizer.zero_grad()   # zero the gradient buffers\n",
    "output = net(input)\n",
    "loss = criterion(output, target_new)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e5a53db6",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found dtype Double but expected Float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-97c9a77c33c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_new\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Found dtype Double but expected Float"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = torch.optim.Adam(params, lr=0.01, betas=(0.9, 0.999), eps=1e-09, weight_decay=0.1, amsgrad=False)  #adam optimizer\n",
    "    \n",
    "for i in range(200):\n",
    "    optimizer.zero_grad()   # zero the gradient buffers\n",
    "    output = net(input)\n",
    "    loss = criterion(output, target_new)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba61ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=x[1000:2000,:]\n",
    "print(x_test.shape)\n",
    "y1=y[0:1,:,1000:2000,:,0:1]\n",
    "#(Nrepeat, Ntimesteps, Nx, output_dim, 2)  <-- 2 = (final position, final velocity)\n",
    "y1_np=torch.from_numpy(y1)\n",
    "y1=torch.transpose(y1_np,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae78d6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "y4=y1.squeeze(0).squeeze(3)\n",
    "print(y4.shape)\n",
    "\n",
    "y_test=y4[:,F:F+1,:]\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c198fd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122b0a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=torch.tensor(x_test)\n",
    "test_out=net(x_test)\n",
    "#LOSS = criterion(test_out, y_test)\n",
    "print(test_out)\n",
    "print(y_test)\n",
    "y_test_new=torch.transpose(y_test,1,2).squeeze(2)\n",
    "test_loss=criterion(y_test_new,test_out)\n",
    "print(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262c25c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_test_new.flatten(), 5*test_out.detach().numpy().flatten(), '.')\n",
    "plt.title('Training')\n",
    "plt.xlabel('y')\n",
    "plt.ylabel('y_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7489bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dt_exp_comparison(yexp, ypred):\n",
    "\n",
    "    fig, axs = plt.subplots(nrows = 3, ncols = 3, figsize = [10,8], dpi = 100, sharex=True, sharey=True)\n",
    "    for i in range(9):\n",
    "        plt.sca(axs.flatten()[i])\n",
    "        plt.plot(ypred[i], '.-', lw = 1, c = 'k', alpha = 0.5, label = 'digital twin prediction')\n",
    "        plt.plot(yexp[i], '.-', lw = 1, c = 'b', alpha = 0.5, label = 'experimental outcome')\n",
    "        plt.xlabel('# pendulum')\n",
    "        plt.ylabel('output angle')\n",
    "        plt.title(f'Initial conditions {i}')\n",
    "        plt.grid()\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('img/coupled_pendula_dt_examples.png')\n",
    "    plt.show()\n",
    "    \n",
    "plot_dt_exp_comparison(y_test_new,5*test_out.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb087b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net2(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net2, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Linear(14, 120)\n",
    "        self.layer2 = nn.Linear(120, 120)\n",
    "        self.layer3 = nn.Linear(120, 120)\n",
    "        self.layer4 = nn.Linear(120, 84)\n",
    "        self.layer5 = nn.Linear(84, 42)\n",
    "        self.layer6 = nn.Linear(42, 7)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        \n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = x+F.relu(self.layer2(x))\n",
    "        x = x+F.relu(self.layer3(x))\n",
    "        x = F.relu(self.layer4(x))\n",
    "        x = F.tanh(self.layer5(x))\n",
    "        x = F.relu(self.layer6(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "net2 = Net2()\n",
    "print(net2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c01430",
   "metadata": {},
   "source": [
    "params2 = list(net2.parameters())\n",
    "print(len(params2))\n",
    "print(params2[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b558da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data=torch.tensor(x)\n",
    "input = x_data\n",
    "out = net2(input)\n",
    "print(out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8ad80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target=y1[0:1000,:,:]\n",
    "target_new=target.view(1000,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5261484e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = torch.optim.Adam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-06, weight_decay=0.1, amsgrad=False)  #adam optimizer\n",
    "    \n",
    "for i in range(200):\n",
    "    optimizer.zero_grad()   # zero the gradient buffers\n",
    "    output = net2(input)\n",
    "    loss = criterion(output, target_new)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e684b295",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
